{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## End to end AML and ADB Pipeline\n",
        "\n",
        "In this notebook, I'll demonstrate how to leverage Azure ML Datasets to approach a data mesh strategy for any model development activities across different compute targets, including databricks and AzureML by leveraging `Azure ML Pipelines`. This notebook is the extension to the first [notebook](pipeline_def.ipynb) by adding the AutoML and Model Registration step as subsequent steps to the DatabriksStep.\n",
        "\n",
        "<div style=\"text-align:center; width: 1000px\"><img src=\"./assets/pipeline_automl.jpg\" /></div>\n",
        "\n",
        "*The AML Piepline Image*\n",
        "\n",
        "In order to run this example, you need to have an AML Workspace with a Compute Cluster. In addition, you need an Azure Databricks cluster with ML Runtime. The cluster needs to have azureml-sdk[databricks] package installed.\n",
        "\n",
        "The overal idea is to create data lineage for the entire life cycle of a model, which starts with data processing and ends with model registration and deployment.\n",
        "A simple training excersice is picked to focus mostly on the use of AML Dataset.\n",
        "\n",
        "In this example, The data preprocessing happens on Databricks through `DatabricksStep` and the model training takes place on an AML Compute through `PythonScriptStep`. \n",
        "\n",
        "The first step receives three input AML Datasets and prepared for a model training excersice in the DatabricksStep. Later the final dataframe is saved as a `Parquet`. Finally, the saved data is registered as a AML Dataset as `TabularDataset` in `Parquet` file format. The spark dataframe is then registered in Azure Databricks `Feature Store` to be natively retrieved within Databricks.\n",
        "\n",
        "Every time the DatabricksStep is executed, two new datasets are generated called `feature_titanic_train` and `feature_titanic_test` as AML TabularDatasets that are then passed to the AutoMLStep. If the allow_reuse parameter on the `DatabricksStep` constructor is set to True, then the output datasets registered from the previous run will be reused for the next step.\n",
        "\n",
        "<div style=\"text-align:center; width: 500px\"><img src=\"./assets/ADBStep_automl.jpg\" /></div>\n",
        "\n",
        "*ADB Step details page; the input and output datasets.*\n",
        "\n",
        "Below is the output dataset which is registered as a Databricks Feature store:\n",
        "\n",
        "<div style=\"text-align:center; width: 500px\"><img src=\"./assets/DatabricksFeatureStoreAutoML.jpg\" /></div>\n",
        "\n",
        "*Feature Titanic dataset registered as an Azure Databricks Feature Store*\n",
        "\n",
        "The registered `AML Dataset`s are passed to the subsequent `AutoMLStep` which is meant for training and testing of the AutoML Model. The data is read based on the incoming dataset type. Currently, AutoML supports csv and parquet for tabular datasets. Later the Delta will be supported as input datatype.\n",
        "\n",
        "<div style=\"text-align:center; width: 1000px\"><img src=\"./assets/AutoMLStep.jpg\" /></div>\n",
        "\n",
        "*AML Step details page; the input and output datasets.*\n",
        "\n",
        "Once the AutoMLStep is completed, the best model is passed to a subsequent step to register the best model. To register the model, the `AML Dataset` objects (one for training and one for testing) are passed as parameters to the `Model.register` function. This links the model to the datasets that were used the AutoML experiment.\n",
        "\n",
        "<div style=\"text-align:center; width: 1000px\"><img src=\"./assets/Model_AutoML.jpg\" /></div>\n",
        "\n",
        "*Registered Model data tab; link to the feature_titanic AML Dataset.*\n",
        "\n",
        "This also helps us to connect the `AML Dataset` to the models as well.\n",
        "\n",
        "<div style=\"text-align:center; width: 1000px\"><img src=\"./assets/DatasetToModelAutoML.jpg\" /></div>\n",
        "\n",
        "*Model tab of the Featurized AML Dataset; link to the titanic_model AML Model.*\n",
        "\n",
        "During the lifecycle of the model and dataset, we leveraged `tags` parameter of the `register` function of `AML Datasets` and `AML Models`. This allows us to always keep and attach important parameters to the model and dataset objects. Parameters such as `dataset schema`, `input dataset`, `run_id`, etc.\n",
        "\n",
        "<div style=\"text-align:center; width: 500px\"><img src=\"./assets/DatasetTags.jpg\" /></div>\n",
        "\n",
        "*Taggs of the feature_titanic train and test datasets. This identifies the input datasets, databricks feature store, data types of the final pandas dataframe, etc.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SDK version: 1.48.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.core.runconfig import JarLibrary\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import DatabricksStep, PythonScriptStep\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learningmain\n",
            "learning\n",
            "eastus\n",
            "dac8073e-1c2d-4a7d-a53b-c3655e291d58\n"
          ]
        }
      ],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compute target ADB already exists\n"
          ]
        }
      ],
      "source": [
        "db_compute_name = \"ADB\" # Databricks compute name\n",
        "\n",
        "databricks_compute = DatabricksCompute(workspace=ws, name=db_compute_name)\n",
        "print('Compute target {} already exists'.format(db_compute_name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datastore workspaceblobstore will be used\n"
          ]
        }
      ],
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\n",
        "\n",
        "def_blob_store = ws.get_default_datastore()\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def register_dataset(datastore, dataset_name):\n",
        "    remote_path = f'dataset-demo/{dataset_name}/'\n",
        "    local_path = './data/titanic.csv'\n",
        "    datastore.upload_files(files = [local_path],\n",
        "                       target_path = remote_path,\n",
        "                       overwrite = True,\n",
        "                       show_progress = False)\n",
        "    \n",
        "    dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, remote_path)])\n",
        "    dataset = dataset.register(ws, name=dataset_name, create_new_version=True)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "ds_titanic_1 = register_dataset(def_blob_store, 'titanic_1')\n",
        "ds_titanic_2 = register_dataset(def_blob_store, 'titanic_2')\n",
        "ds_titanic_3 = register_dataset(def_blob_store, 'titanic_3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1651693315206
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "ds_step_1_train = PipelineData(\"output_train\", datastore=def_blob_store).as_dataset()\n",
        "ds_step_1_test = PipelineData(\"output_test\", datastore=def_blob_store).as_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "source_directory = \"./scripts\"\n",
        "\n",
        "databricks_script_name = \"adb_run_automl.py\"\n",
        "\n",
        "feature_dataset_name_train = \"feature_titanic_train\"\n",
        "feature_dataset_name_test = \"feature_titanic_test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1651694246481
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "dbNbStep = DatabricksStep(\n",
        "    name=\"ADB_Feature_Eng\",\n",
        "    outputs=[ds_step_1_train, ds_step_1_test],\n",
        "    compute_target=databricks_compute,\n",
        "    existing_cluster_id=\"0227-163903-wnphf6fm\",\n",
        "    python_script_params=[\"--feature_set_1\", ds_titanic_1.name,\n",
        "                          \"--feature_set_2\", ds_titanic_2.name,\n",
        "                          \"--feature_set_3\", ds_titanic_3.name,\n",
        "                          '--output_datastore_name', def_blob_store.name,\n",
        "                          \"--output_train_feature_set_name\", feature_dataset_name_train, \n",
        "                          \"--output_test_feature_set_name\", feature_dataset_name_test],\n",
        "    permit_cluster_restart=True,\n",
        "    python_script_name=databricks_script_name,\n",
        "    source_directory=source_directory,\n",
        "    run_name='ADB_Feature_Eng',\n",
        "    allow_reuse=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_name = \"cpu-cluster\"\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AutoML config created.\n"
          ]
        }
      ],
      "source": [
        "# Change iterations to a reasonable number (50) to get better accuracy\n",
        "automl_settings = {\n",
        "    \"iteration_timeout_minutes\" : 10,\n",
        "    \"iterations\" : 2,\n",
        "    \"primary_metric\" : 'AUC_weighted',\n",
        "    \"n_cross_validations\": 5\n",
        "}\n",
        "\n",
        "automl_config = AutoMLConfig(task = 'classification',\n",
        "                             debug_log = 'automated_ml_errors.log',\n",
        "                             compute_target = compute_target,\n",
        "                             featurization = 'auto',\n",
        "                             training_data = ds_step_1_train.parse_parquet_files(),\n",
        "                             test_data = ds_step_1_test.parse_parquet_files(),\n",
        "                             label_column_name = 'Survived',\n",
        "                             **automl_settings)\n",
        "                             \n",
        "print(\"AutoML config created.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = ws.get_default_datastore()\n",
        "metrics_output_name = 'metrics_output'\n",
        "best_model_output_name = 'best_model_output'\n",
        "\n",
        "metrics_data = PipelineData(name='metrics_data',\n",
        "                           datastore=ds,\n",
        "                           pipeline_output_name=metrics_output_name,\n",
        "                           training_output=TrainingOutput(type='Metrics'))\n",
        "model_data = PipelineData(name='model_data',\n",
        "                           datastore=ds,\n",
        "                           pipeline_output_name=best_model_output_name,\n",
        "                           training_output=TrainingOutput(type='Model'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainWithAutomlStep created.\n"
          ]
        }
      ],
      "source": [
        "train_automlStep = AutoMLStep(name='AutoML_Classification',\n",
        "                                 automl_config=automl_config,\n",
        "                                 outputs=[metrics_data, model_data],\n",
        "                                 allow_reuse=True)\n",
        "\n",
        "print(\"trainWithAutomlStep created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "reg_comp_name = \"small-cluster\"\n",
        "reg_compute_target = ComputeTarget(workspace=ws, name=reg_comp_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'./scripts'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "conda_dep = CondaDependencies()\n",
        "conda_dep.add_pip_package(\"azureml-sdk\")\n",
        "\n",
        "rcfg = RunConfiguration(conda_dependencies=conda_dep)\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       inputs=[model_data],\n",
        "                                               # ds_step_1_train.parse_parquet_files().as_named_input('input_train'), \n",
        "                                               # ds_step_1_test.parse_parquet_files().as_named_input('input_test')],\n",
        "                                       compute_target=reg_compute_target,\n",
        "                                       arguments=[\"--saved-model\", model_data, \n",
        "                                                  '--model-name' , 'titanic_model', \n",
        "                                                  '--featureset-name-train', feature_dataset_name_train, \n",
        "                                                  '--featureset-name-test', feature_dataset_name_test],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "# register_model_step.run_after(train_automlStep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1651694252978
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created step ADB_Feature_Eng [cbeb94e0][7352a862-145b-44be-af51-3bd4bcdc42f4], (This step is eligible to reuse a previous run's output)\n",
            "Created step AutoML_Classification [d3efd02b][47174161-3cb2-4585-aff8-6fc49a4f0363], (This step will run and generate new outputs)Created step Register_Best_Model [1036c161][4f39d18a-74c7-4387-b32d-d45a457de728], (This step is eligible to reuse a previous run's output)\n",
            "\n",
            "Submitted PipelineRun 05f9992e-7a6e-47d3-ae92-2e3897cf7b16\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/05f9992e-7a6e-47d3-ae92-2e3897cf7b16?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/learning/workspaces/learningmain&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n"
          ]
        }
      ],
      "source": [
        "steps = [dbNbStep, train_automlStep, register_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\n",
        "pipeline_run = Experiment(ws, 'DB_FeatureStore_AutoML_Register').submit(pipeline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>DB_FeatureStore_AutoML_Register</td><td>05f9992e-7a6e-47d3-ae92-2e3897cf7b16</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/05f9992e-7a6e-47d3-ae92-2e3897cf7b16?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/learning/workspaces/learningmain&amp;tid=16b3c013-d300-468d-ac64-7eda0820b6d3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: DB_FeatureStore_AutoML_Register,\n",
              "Id: 05f9992e-7a6e-47d3-ae92-2e3897cf7b16,\n",
              "Type: azureml.PipelineRun,\n",
              "Status: Preparing)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PipelineRunId: 05f9992e-7a6e-47d3-ae92-2e3897cf7b16\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/05f9992e-7a6e-47d3-ae92-2e3897cf7b16?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/learning/workspaces/learningmain&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
            "PipelineRun Status: NotStarted\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: 0221259c-4d01-439f-be01-6e0cc77bc4c6\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/0221259c-4d01-439f-be01-6e0cc77bc4c6?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/learning/workspaces/learningmain&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
            "StepRun( ADB_Feature_Eng ) Status: NotStarted\n",
            "StepRun( ADB_Feature_Eng ) Status: Running\n",
            "\n",
            "StepRun(ADB_Feature_Eng) Execution Summary\n",
            "===========================================\n",
            "StepRun( ADB_Feature_Eng ) Status: Finished\n",
            "{'runId': '0221259c-4d01-439f-be01-6e0cc77bc4c6', 'target': 'ADB', 'status': 'Completed', 'startTimeUtc': '2023-03-07T17:30:48.189026Z', 'endTimeUtc': '2023-03-07T17:32:28.508677Z', 'services': {}, 'properties': {'ContentSnapshotId': '51c8ef03-5173-4e3a-a57d-0a15b6cd994b', 'StepType': 'DataBricksStep', 'ComputeTargetType': 'DataBricks', 'azureml.moduleid': '7352a862-145b-44be-af51-3bd4bcdc42f4', 'azureml.moduleName': 'ADB_Feature_Eng', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'cbeb94e0', 'azureml.pipelinerunid': '05f9992e-7a6e-47d3-ae92-2e3897cf7b16', 'azureml.pipeline': '05f9992e-7a6e-47d3-ae92-2e3897cf7b16', 'azureml.pipelineComponent': 'masterdatabrickscloud', 'azureml.joblink': 'https://adb-7959016608908952.12.azuredatabricks.net/?o=7959016608908952#job/405038759210688/run/262206'}, 'inputDatasets': [{'dataset': {'id': '046009ff-a115-47d4-a81d-c6e0729b20c9'}, 'consumptionDetails': {'type': 'Reference'}}, {'dataset': {'id': '88f5f87b-d4e8-424d-baf6-68659398d281'}, 'consumptionDetails': {'type': 'Reference'}}, {'dataset': {'id': '25e28a2c-2a70-4cb5-870c-103799628813'}, 'consumptionDetails': {'type': 'Reference'}}], 'outputDatasets': [{'identifier': {'savedId': '737b18b3-2b49-48a4-84d3-b54a2098fb5b', 'registeredId': '5fceeaab-66d1-449e-ab9d-4e3a7408f756', 'registeredVersion': '1'}, 'outputType': 'Reference', 'dataset': {\n",
            "  \"source\": [\n",
            "    \"('workspaceblobstore', '/azureml/0221259c-4d01-439f-be01-6e0cc77bc4c6/output_train/*.parquet')\"\n",
            "  ],\n",
            "  \"definition\": [\n",
            "    \"GetDatastoreFiles\",\n",
            "    \"ReadParquetFile\",\n",
            "    \"DropColumns\"\n",
            "  ],\n",
            "  \"registration\": {\n",
            "    \"id\": \"737b18b3-2b49-48a4-84d3-b54a2098fb5b\",\n",
            "    \"name\": \"feature_titanic_train\",\n",
            "    \"version\": 1,\n",
            "    \"description\": \"feature_titanic_train featurized data\",\n",
            "    \"tags\": {\n",
            "      \"input_datasets\": \"['titanic_1: 1', 'titanic_2: 1', 'titanic_3: 1']\",\n",
            "      \"regisitered_at\": \"2023-03-07 17:32:18\",\n",
            "      \"delta_feature_name\": \"features.feature_titanic_train\",\n",
            "      \"run_id\": \"05f9992e-7a6e-47d3-ae92-2e3897cf7b16\",\n",
            "      \"dtypes\": \"{'PassengerId': 'int64', 'Pclass': 'int64', 'Sex': 'int64', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Fare': 'float64', 'id': 'object', 'Survived': 'int64'}\"\n",
            "    },\n",
            "    \"workspace\": \"Workspace.create(name='learningmain', subscription_id='dac8073e-1c2d-4a7d-a53b-c3655e291d58', resource_group='learning')\"\n",
            "  }\n",
            "}}, {'identifier': {'savedId': '3b698e61-3224-4340-a4f4-8a3f82783967', 'registeredId': 'f74c1f7e-04f0-4e50-a83b-dfdea0eb0011', 'registeredVersion': '1'}, 'outputType': 'Reference', 'dataset': {\n",
            "  \"source\": [\n",
            "    \"('workspaceblobstore', '/azureml/0221259c-4d01-439f-be01-6e0cc77bc4c6/output_test/*.parquet')\"\n",
            "  ],\n",
            "  \"definition\": [\n",
            "    \"GetDatastoreFiles\",\n",
            "    \"ReadParquetFile\",\n",
            "    \"DropColumns\"\n",
            "  ],\n",
            "  \"registration\": {\n",
            "    \"id\": \"3b698e61-3224-4340-a4f4-8a3f82783967\",\n",
            "    \"name\": \"feature_titanic_test\",\n",
            "    \"version\": 1,\n",
            "    \"description\": \"feature_titanic_test featurized data\",\n",
            "    \"tags\": {\n",
            "      \"input_datasets\": \"['titanic_1: 1', 'titanic_2: 1', 'titanic_3: 1']\",\n",
            "      \"regisitered_at\": \"2023-03-07 17:32:19\",\n",
            "      \"delta_feature_name\": \"features.feature_titanic_test\",\n",
            "      \"run_id\": \"05f9992e-7a6e-47d3-ae92-2e3897cf7b16\",\n",
            "      \"dtypes\": \"{'PassengerId': 'int64', 'Pclass': 'int64', 'Sex': 'int64', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Fare': 'float64', 'id': 'object', 'Survived': 'int64'}\"\n",
            "    },\n",
            "    \"workspace\": \"Workspace.create(name='learningmain', subscription_id='dac8073e-1c2d-4a7d-a53b-c3655e291d58', resource_group='learning')\"\n",
            "  }\n",
            "}}], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://learningmain7216512787.blob.core.windows.net/azureml/ExperimentRun/dcid.0221259c-4d01-439f-be01-6e0cc77bc4c6/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=Ipetv0D5ggSHWbdlVmCoT81F8XRxRfFtSF5ShOaeS1E%3D&skoid=a9b97d81-d296-4304-a51e-036455d6b2cb&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-03-07T16%3A05%3A48Z&ske=2023-03-09T00%3A15%3A48Z&sks=b&skv=2019-07-07&st=2023-03-07T17%3A20%3A46Z&se=2023-03-08T01%3A30%3A46Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://learningmain7216512787.blob.core.windows.net/azureml/ExperimentRun/dcid.0221259c-4d01-439f-be01-6e0cc77bc4c6/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=237L1GcTWWbNrIh2veWjLlgJEvaGL0EeDgrm3PZyWzY%3D&skoid=a9b97d81-d296-4304-a51e-036455d6b2cb&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-03-07T16%3A05%3A48Z&ske=2023-03-09T00%3A15%3A48Z&sks=b&skv=2019-07-07&st=2023-03-07T17%3A20%3A46Z&se=2023-03-08T01%3A30%3A46Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://learningmain7216512787.blob.core.windows.net/azureml/ExperimentRun/dcid.0221259c-4d01-439f-be01-6e0cc77bc4c6/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=cnCqMDnf3ZdR7a5R81XzipvuWgO8OcYgtzRjZ4S4mwU%3D&skoid=a9b97d81-d296-4304-a51e-036455d6b2cb&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-03-07T16%3A05%3A48Z&ske=2023-03-09T00%3A15%3A48Z&sks=b&skv=2019-07-07&st=2023-03-07T17%3A20%3A46Z&se=2023-03-08T01%3A30%3A46Z&sp=r'}, 'submittedBy': 'Hossein Sarshar'}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "StepRunId: 26247021-a31d-4157-b31c-87e19f2becb0\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/26247021-a31d-4157-b31c-87e19f2becb0?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/learning/workspaces/learningmain&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
            "StepRun( AutoML_Classification ) Status: NotStarted\n",
            "StepRun( AutoML_Classification ) Status: Running\n",
            "\n",
            "StepRun(AutoML_Classification) Execution Summary\n",
            "=================================================\n",
            "StepRun( AutoML_Classification ) Status: Finished\n",
            "{'runId': '26247021-a31d-4157-b31c-87e19f2becb0', 'target': 'cpu-cluster', 'status': 'Completed', 'startTimeUtc': '2023-03-07T17:32:43.736486Z', 'endTimeUtc': '2023-03-07T17:40:21.858102Z', 'services': {}, 'properties': {'ContentSnapshotId': 'ebc277cb-3c0b-4a50-b1f7-7b97367dcf41', 'StepType': 'AutoMLStep', 'azureml.moduleid': '47174161-3cb2-4585-aff8-6fc49a4f0363', 'azureml.moduleName': 'AutoML_Classification', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'd3efd02b', 'azureml.pipelinerunid': '05f9992e-7a6e-47d3-ae92-2e3897cf7b16', 'azureml.pipeline': '05f9992e-7a6e-47d3-ae92-2e3897cf7b16', 'azureml.pipelineComponent': 'masterautomlcloud', 'num_iterations': '2', 'training_type': 'TrainFull', 'acquisition_function': 'EI', 'metrics': 'accuracy', 'primary_metric': 'AUC_weighted', 'train_split': '0', 'MaxTimeSeconds': '600', 'acquisition_parameter': '0', 'num_cross_validation': '5', 'target': 'cpu-cluster', 'RawAMLSettingsString': None, 'AMLSettingsJsonString': '{\"path\": null, \"name\": \"placeholder\", \"subscription_id\": \"dac8073e-1c2d-4a7d-a53b-c3655e291d58\", \"resource_group\": \"learning\", \"workspace_name\": \"learningmain\", \"region\": \"eastus\", \"compute_target\": \"cpu-cluster\", \"spark_service\": null, \"azure_service\": null, \"many_models\": false, \"pipeline_fetch_max_batch_size\": 1, \"enable_batch_run\": false, \"enable_parallel_run\": false, \"num_procs\": null, \"enable_run_restructure\": false, \"start_auxiliary_runs_before_parent_complete\": true, \"enable_code_generation\": true, \"iterations\": 2, \"primary_metric\": \"AUC_weighted\", \"task_type\": \"classification\", \"positive_label\": null, \"data_script\": null, \"test_size\": 0.0, \"test_include_predictions_only\": false, \"validation_size\": 0.0, \"n_cross_validations\": 5, \"y_min\": null, \"y_max\": null, \"num_classes\": null, \"featurization\": \"auto\", \"_ignore_package_version_incompatibilities\": false, \"is_timeseries\": false, \"max_cores_per_iteration\": 1, \"max_concurrent_iterations\": 1, \"iteration_timeout_minutes\": 10, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"experiment_timeout_minutes\": 8640, \"experiment_exit_score\": null, \"partition_column_names\": null, \"whitelist_models\": null, \"blacklist_algos\": null, \"supported_models\": [\"LogisticRegression\", \"LightGBM\", \"ExtremeRandomTrees\", \"TensorFlowDNN\", \"AveragedPerceptronClassifier\", \"GradientBoosting\", \"LinearSVM\", \"BernoulliNaiveBayes\", \"KNN\", \"TensorFlowLinearClassifier\", \"SGD\", \"TabnetClassifier\", \"SVM\", \"DecisionTree\", \"RandomForest\", \"MultinomialNaiveBayes\", \"XGBoostClassifier\"], \"private_models\": [], \"auto_blacklist\": true, \"blacklist_samples_reached\": false, \"exclude_nan_labels\": true, \"verbosity\": 20, \"_debug_log\": \"automated_ml_errors.log\", \"show_warnings\": false, \"model_explainability\": true, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"enable_onnx_compatible_models\": false, \"enable_split_onnx_featurizer_estimator_models\": false, \"vm_type\": \"STANDARD_DS3_V2\", \"telemetry_verbosity\": 20, \"send_telemetry\": true, \"enable_dnn\": false, \"scenario\": \"AutoML\", \"environment_label\": null, \"save_mlflow\": false, \"enable_categorical_indicators\": false, \"force_text_dnn\": false, \"enable_feature_sweeping\": true, \"enable_early_stopping\": true, \"early_stopping_n_iters\": 10, \"arguments\": null, \"dataset_id\": null, \"hyperdrive_config\": null, \"validation_dataset_id\": null, \"run_source\": null, \"metrics\": null, \"enable_metric_confidence\": false, \"enable_ensembling\": false, \"enable_stack_ensembling\": false, \"ensemble_iterations\": null, \"enable_tf\": false, \"enable_subsampling\": false, \"subsample_seed\": null, \"enable_nimbusml\": false, \"enable_streaming\": false, \"force_streaming\": false, \"track_child_runs\": true, \"n_best_runs\": 1, \"allowed_private_models\": [], \"label_column_name\": \"Survived\", \"weight_column_name\": null, \"cv_split_column_names\": null, \"enable_local_managed\": false, \"_local_managed_run_id\": null, \"cost_mode\": 1, \"lag_length\": 0, \"metric_operation\": \"maximize\", \"preprocess\": true}', 'DataPrepJsonString': '{\\\\\"training_data\\\\\":\\\\\"{\\\\\\\\n  \\\\\\\\\\\\\"blocks\\\\\\\\\\\\\": [\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"7b2528c0-3b4e-4303-b8cc-d18863dce17c\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.GetDatastoreFilesBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"datastores\\\\\\\\\\\\\": [\\\\\\\\n          {\\\\\\\\n            \\\\\\\\\\\\\"datastoreName\\\\\\\\\\\\\": \\\\\\\\\\\\\"workspaceblobstore\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"path\\\\\\\\\\\\\": \\\\\\\\\\\\\"azureml/0221259c-4d01-439f-be01-6e0cc77bc4c6/output_train\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"resourceGroup\\\\\\\\\\\\\": \\\\\\\\\\\\\"learning\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"subscription\\\\\\\\\\\\\": \\\\\\\\\\\\\"dac8073e-1c2d-4a7d-a53b-c3655e291d58\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"workspaceName\\\\\\\\\\\\\": \\\\\\\\\\\\\"learningmain\\\\\\\\\\\\\"\\\\\\\\n          }\\\\\\\\n        ]\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"9b32ccba-2e41-40b9-83e5-1fabaa292183\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.ExpressionFilterBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"expression\\\\\\\\\\\\\": {\\\\\\\\\\\\\"r\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Invoke\\\\\\\\\\\\\",[{\\\\\\\\\\\\\"r\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Identifier\\\\\\\\\\\\\",\\\\\\\\\\\\\"String_EndsWith\\\\\\\\\\\\\"]},[{\\\\\\\\\\\\\"r\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Invoke\\\\\\\\\\\\\",[{\\\\\\\\\\\\\"r\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Identifier\\\\\\\\\\\\\",\\\\\\\\\\\\\"GetResourceName\\\\\\\\\\\\\"]},[{\\\\\\\\\\\\\"r\\\\\\\\\\\\\":[\\\\\\\\\\\\\"RecordField\\\\\\\\\\\\\",[{\\\\\\\\\\\\\"r\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Identifier\\\\\\\\\\\\\",\\\\\\\\\\\\\"row\\\\\\\\\\\\\"]},\\\\\\\\\\\\\"Path\\\\\\\\\\\\\"]]}]]]},\\\\\\\\\\\\\".parquet\\\\\\\\\\\\\"]]]}\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"d30191eb-8882-4324-b922-df2aea7a9cee\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.ReadParquetFileBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"preview\\\\\\\\\\\\\": false\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"7cac62a4-f204-45a8-8c48-a4687eeb563a\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.DropColumnsBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"columns\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\"type\\\\\\\\\\\\\": 0,\\\\\\\\n          \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\n            \\\\\\\\\\\\\"selectedColumns\\\\\\\\\\\\\": [\\\\\\\\n              \\\\\\\\\\\\\"Path\\\\\\\\\\\\\"\\\\\\\\n            ]\\\\\\\\n          }\\\\\\\\n        }\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    }\\\\\\\\n  ],\\\\\\\\n  \\\\\\\\\\\\\"inspectors\\\\\\\\\\\\\": [],\\\\\\\\n  \\\\\\\\\\\\\"meta\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\"savedDatasetId\\\\\\\\\\\\\": \\\\\\\\\\\\\"71ff9628-0dda-4baf-975a-1436b3493ae7\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"datasetType\\\\\\\\\\\\\": \\\\\\\\\\\\\"tabular\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"subscriptionId\\\\\\\\\\\\\": \\\\\\\\\\\\\"dac8073e-1c2d-4a7d-a53b-c3655e291d58\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"workspaceId\\\\\\\\\\\\\": \\\\\\\\\\\\\"c6541937-0838-4761-b105-c3244fe06898\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"workspaceLocation\\\\\\\\\\\\\": \\\\\\\\\\\\\"eastus\\\\\\\\\\\\\"\\\\\\\\n  }\\\\\\\\n}\\\\\",\\\\\"test_data\\\\\":\\\\\"{\\\\\\\\n  \\\\\\\\\\\\\"blocks\\\\\\\\\\\\\": [\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"7091bdb0-1ea9-4f25-894b-c380ef56dd11\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.GetDatastoreFilesBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"datastores\\\\\\\\\\\\\": [\\\\\\\\n          {\\\\\\\\n            \\\\\\\\\\\\\"datastoreName\\\\\\\\\\\\\": \\\\\\\\\\\\\"workspaceblobstore\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"path\\\\\\\\\\\\\": \\\\\\\\\\\\\"azureml/0221259c-4d01-439f-be01-6e0cc77bc4c6/output_test\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"resourceGroup\\\\\\\\\\\\\": \\\\\\\\\\\\\"learning\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"subscription\\\\\\\\\\\\\": \\\\\\\\\\\\\"dac8073e-1c2d-4a7d-a53b-c3655e291d58\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"workspaceName\\\\\\\\\\\\\": \\\\\\\\\\\\\"learningmain\\\\\\\\\\\\\"\\\\\\\\n          }\\\\\\\\n        ]\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"e09a4fda-2f89-4c7a-8ece-f677fdc547c0\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.ExpressionFilterBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"expression\\\\\\\\\\\\\": {\\\\\\\\\\\\\"r\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Invoke\\\\\\\\\\\\\",[{\\\\\\\\\\\\\"r\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Identifier\\\\\\\\\\\\\",\\\\\\\\\\\\\"String_EndsWith\\\\\\\\\\\\\"]},[{\\\\\\\\\\\\\"r\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Invoke\\\\\\\\\\\\\",[{\\\\\\\\\\\\\"r\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Identifier\\\\\\\\\\\\\",\\\\\\\\\\\\\"GetResourceName\\\\\\\\\\\\\"]},[{\\\\\\\\\\\\\"r\\\\\\\\\\\\\":[\\\\\\\\\\\\\"RecordField\\\\\\\\\\\\\",[{\\\\\\\\\\\\\"r\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Identifier\\\\\\\\\\\\\",\\\\\\\\\\\\\"row\\\\\\\\\\\\\"]},\\\\\\\\\\\\\"Path\\\\\\\\\\\\\"]]}]]]},\\\\\\\\\\\\\".parquet\\\\\\\\\\\\\"]]]}\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"15530483-d635-4ef4-a208-a2a1914febdc\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.ReadParquetFileBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"preview\\\\\\\\\\\\\": false\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"4e6cb200-95fc-420c-9901-f118a9c68f74\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.DropColumnsBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"columns\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\"type\\\\\\\\\\\\\": 0,\\\\\\\\n          \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\n            \\\\\\\\\\\\\"selectedColumns\\\\\\\\\\\\\": [\\\\\\\\n              \\\\\\\\\\\\\"Path\\\\\\\\\\\\\"\\\\\\\\n            ]\\\\\\\\n          }\\\\\\\\n        }\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    }\\\\\\\\n  ],\\\\\\\\n  \\\\\\\\\\\\\"inspectors\\\\\\\\\\\\\": [],\\\\\\\\n  \\\\\\\\\\\\\"meta\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\"savedDatasetId\\\\\\\\\\\\\": \\\\\\\\\\\\\"5795eef8-26ce-4538-9e79-3c9ce8f7e2f3\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"datasetType\\\\\\\\\\\\\": \\\\\\\\\\\\\"tabular\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"subscriptionId\\\\\\\\\\\\\": \\\\\\\\\\\\\"dac8073e-1c2d-4a7d-a53b-c3655e291d58\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"workspaceId\\\\\\\\\\\\\": \\\\\\\\\\\\\"c6541937-0838-4761-b105-c3244fe06898\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"workspaceLocation\\\\\\\\\\\\\": \\\\\\\\\\\\\"eastus\\\\\\\\\\\\\"\\\\\\\\n  }\\\\\\\\n}\\\\\",\\\\\"activities\\\\\":\\\\\"0\\\\\"}', 'EnableSubsampling': 'False', 'runTemplate': 'AutoML', 'Orchestrator': 'AutoML', 'ClientType': 'Others', 'PlatformVersion': 'DPV1', '_aml_system_scenario_identification': 'Remote.Parent', 'ClientSdkVersion': '1.48.0.post2', 'root_attribution': 'azureml.StepRun', 'snapshotId': 'ebc277cb-3c0b-4a50-b1f7-7b97367dcf41', 'SetupRunId': '26247021-a31d-4157-b31c-87e19f2becb0_setup', 'SetupRunContainerId': 'dcid.26247021-a31d-4157-b31c-87e19f2becb0_setup', 'FeaturizationRunJsonPath': 'featurizer_container.json', 'FeaturizationRunId': '26247021-a31d-4157-b31c-87e19f2becb0_featurize', 'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"has_extra_col\": true, \"dataset_classes\": 2, \"dataset_features\": 20, \"dataset_samples\": 2138, \"single_frequency_class_detected\": false}', 'ModelExplainRunId': '26247021-a31d-4157-b31c-87e19f2becb0_ModelExplain'}, 'inputDatasets': [{'dataset': {'id': '71ff9628-0dda-4baf-975a-1436b3493ae7'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}, {'dataset': {'id': '5795eef8-26ce-4538-9e79-3c9ce8f7e2f3'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'test_data', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://learningmain7216512787.blob.core.windows.net/azureml/ExperimentRun/dcid.26247021-a31d-4157-b31c-87e19f2becb0/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=TeuSYPcbIwwiO5cWbsO8Roilp%2BrjSKKUIZO%2FB0HSHVE%3D&skoid=a9b97d81-d296-4304-a51e-036455d6b2cb&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-03-07T16%3A05%3A48Z&ske=2023-03-09T00%3A15%3A48Z&sks=b&skv=2019-07-07&st=2023-03-07T17%3A27%3A36Z&se=2023-03-08T01%3A37%3A36Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://learningmain7216512787.blob.core.windows.net/azureml/ExperimentRun/dcid.26247021-a31d-4157-b31c-87e19f2becb0/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=rfqmPH16VSTCuVL8BcG7kMGIBU0TWgkRzk0OHIpyN9w%3D&skoid=a9b97d81-d296-4304-a51e-036455d6b2cb&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-03-07T16%3A05%3A48Z&ske=2023-03-09T00%3A15%3A48Z&sks=b&skv=2019-07-07&st=2023-03-07T17%3A27%3A36Z&se=2023-03-08T01%3A37%3A36Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://learningmain7216512787.blob.core.windows.net/azureml/ExperimentRun/dcid.26247021-a31d-4157-b31c-87e19f2becb0/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=kSgNRtt%2BIwxeqYAUsmIqx0lPdgx8Gh1vnHVcOt9yibA%3D&skoid=a9b97d81-d296-4304-a51e-036455d6b2cb&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-03-07T16%3A05%3A48Z&ske=2023-03-09T00%3A15%3A48Z&sks=b&skv=2019-07-07&st=2023-03-07T17%3A27%3A36Z&se=2023-03-08T01%3A37%3A36Z&sp=r'}, 'submittedBy': 'Hossein Sarshar'}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "StepRunId: 858e3856-05cb-4062-b446-d0351cf2dab1\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/858e3856-05cb-4062-b446-d0351cf2dab1?wsid=/subscriptions/dac8073e-1c2d-4a7d-a53b-c3655e291d58/resourcegroups/learning/workspaces/learningmain&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
            "StepRun( Register_Best_Model ) Status: NotStarted\n",
            "\n",
            "Streaming azureml-logs/20_image_build_log.txt\n",
            "=============================================\n",
            "2023/03/07 17:40:40 Downloading source code...\n",
            "2023/03/07 17:40:41 Finished downloading source code\n",
            "2023/03/07 17:40:41 Creating Docker network: acb_default_network, driver: 'bridge'\n",
            "2023/03/07 17:40:41 Successfully set up Docker network: acb_default_network\n",
            "2023/03/07 17:40:41 Setting up Docker configuration...\n",
            "2023/03/07 17:40:42 Successfully set up Docker configuration\n",
            "2023/03/07 17:40:42 Logging in to registry: c654193708384761b105c3244fe06898.azurecr.io\n",
            "2023/03/07 17:40:43 Successfully logged into c654193708384761b105c3244fe06898.azurecr.io\n",
            "2023/03/07 17:40:43 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2023/03/07 17:40:43 Scanning for dependencies...\n",
            "2023/03/07 17:40:43 Successfully scanned dependencies\n",
            "2023/03/07 17:40:43 Launching container with name: acb_step_0\n",
            "StepRun( Register_Best_Model ) Status: Running\n",
            "Sending build context to Docker daemon  71.68kB\n",
            "\n",
            "Step 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
            "mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b: Pulling from azureml/openmpi4.1.0-ubuntu20.04\n",
            "d7bfe07ed847: Pulling fs layer\n",
            "d1327a17a430: Pulling fs layer\n",
            "69a9739a8058: Pulling fs layer\n",
            "1551e9d33102: Pulling fs layer\n",
            "726392826fd2: Pulling fs layer\n",
            "6ed0c5c30145: Pulling fs layer\n",
            "ea261e5684f6: Pulling fs layer\n",
            "21207d3ea9d3: Pulling fs layer\n",
            "c9a742e394f6: Pulling fs layer\n",
            "b0c9de384791: Pulling fs layer\n",
            "1551e9d33102: Waiting\n",
            "726392826fd2: Waiting\n",
            "6ed0c5c30145: Waiting\n",
            "ea261e5684f6: Waiting\n",
            "21207d3ea9d3: Waiting\n",
            "c9a742e394f6: Waiting\n",
            "b0c9de384791: Waiting\n",
            "69a9739a8058: Verifying Checksum\n",
            "69a9739a8058: Download complete\n",
            "d7bfe07ed847: Verifying Checksum\n",
            "d7bfe07ed847: Download complete\n",
            "726392826fd2: Verifying Checksum\n",
            "726392826fd2: Download complete\n",
            "1551e9d33102: Verifying Checksum\n",
            "1551e9d33102: Download complete\n",
            "ea261e5684f6: Verifying Checksum\n",
            "ea261e5684f6: Download complete\n",
            "21207d3ea9d3: Verifying Checksum\n",
            "21207d3ea9d3: Download complete\n",
            "6ed0c5c30145: Verifying Checksum\n",
            "6ed0c5c30145: Download complete\n",
            "c9a742e394f6: Verifying Checksum\n",
            "c9a742e394f6: Download complete\n",
            "b0c9de384791: Verifying Checksum\n",
            "b0c9de384791: Download complete\n",
            "d7bfe07ed847: Pull complete\n",
            "d1327a17a430: Download complete\n",
            "d1327a17a430: Pull complete\n",
            "69a9739a8058: Pull complete\n",
            "1551e9d33102: Pull complete\n",
            "726392826fd2: Pull complete\n",
            "6ed0c5c30145: Pull complete\n",
            "ea261e5684f6: Pull complete\n",
            "21207d3ea9d3: Pull complete\n",
            "c9a742e394f6: Pull complete\n",
            "b0c9de384791: Pull complete\n",
            "Digest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
            "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
            " ---> b6fd6a8d28e9\n",
            "Step 2/21 : USER root\n",
            " ---> Running in 04e88b4c8900\n",
            "Removing intermediate container 04e88b4c8900\n",
            " ---> ff56342e5a28\n",
            "Step 3/21 : RUN mkdir -p $HOME/.cache\n",
            " ---> Running in 55a4a064c3ca\n",
            "Removing intermediate container 55a4a064c3ca\n",
            " ---> 30ec3bf8067f\n",
            "Step 4/21 : WORKDIR /\n",
            " ---> Running in 4d216ff6a695\n",
            "Removing intermediate container 4d216ff6a695\n",
            " ---> 1457de89a633\n",
            "Step 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
            " ---> 5d892be54ae0\n",
            "Step 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
            " ---> Running in f501327d6d02\n",
            "Removing intermediate container f501327d6d02\n",
            " ---> dd67a92f75c6\n",
            "Step 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
            " ---> 54a62a556121\n",
            "Step 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_3b88d25c0fd444acce6e54de87031c0a -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
            " ---> Running in 3176502d46ba\n",
            "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n"
          ]
        }
      ],
      "source": [
        "pipeline_run.wait_for_completion()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to access the model dataset properties in the production setting for deployment or model consumption\n",
        "\n",
        "Once the pipeline is completed, then you can access the `dataset` information from the registered model by accessing the `datasets` properties of the registered model. In this example, you'll recieve a dictionary that the key is the name provided when the model was registered, `featurized data` in this case.\n",
        "\n",
        "This is helpful if deployment setting of the retrieving dataset characteristics is important. In addition, you can use this method if you like to access the model and dataset information from outside of AML like Databricks or Kubernetes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "model = Model(ws, name='titanic_model')\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model_datasets = model.datasets\n",
        "featurized_data = model_datasets['featurized training data'][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "featurized_data.tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "pdf = featurized_data.to_pandas_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "pdf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Accessing the Dataset from outside of AML\n",
        "\n",
        "In some use-cases, you might want to access the AML Dataset from outside of AML such as Databricks. In order to do this, you can either access the registered data from the `Databricks Feature Store` as is provided in the first step in `DatabricksStep`, or simply calling the `Dataset.get_by_name` function to retrieve the dataset object and start exploring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_feature_dataset = Dataset.get_by_name(ws, feature_dataset_name)\n",
        "\n",
        "pdf_feature_dataset = ds_feature_dataset.to_pandas_dataframe()\n",
        "pdf_feature_dataset.head()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "azureml_py38",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
